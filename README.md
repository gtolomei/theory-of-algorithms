# Teoria degli Algoritmi (2020-2021)

[News](#News) | [Informazioni Generali](#Informazioni-Generali) | [Syllabus](#Syllabus) | [Materiale Didattico](#Materiale-Didattico) |

## News
- **III Appello del 2/9/2021 + IV Appello del 9/9/2021**<br/>
È possibile iscriversi agli appelli su Infostud (verbale **772779** e **772780**, rispettivamente).
- **II Appello del 5/7/2021: Esiti**<br/>
Gli esiti del II appello sono disponibili al seguente [link](./exams/2020-21/2021-07-05_esiti.pdf).
- **II Appello del 5/7/2021: Informazioni Utili**<br/>
L'appello si svolgerà interamente in **modalità a distanza** tramite piattaforma Google Meet, collegandosi al seguente [link](https://meet.google.com/qoi-rzbh-ezf) a partire **dalle ore 9:30**.
- **I Appello del 18/6/2021: Esiti**<br/>
Gli esiti del I appello sono disponibili al seguente [link](./exams/2020-21/2021-06-18_esiti.pdf).
- **I Appello del 18/6/2021: Informazioni Utili**<br/>
L'appello si svolgerà interamente in **modalità a distanza** tramite piattaforma Google Meet, collegandosi al seguente [link](https://meet.google.com/qoi-rzbh-ezf) a partire **dalle ore 9:30**.
- **I Appello del 18/6/2021 + II Appello del 5/7/2021**<br/>
È possibile iscriversi agli appelli su Infostud (verbale **770153** e **770156**, rispettivamente).
- **IMPORTANTE: Ripresa Attività Didattica in Presenza**<br/>
In data **8 aprile 2021** il Senato Accademico ha ratificato il Decreto Rettorale n. 969 del 2 aprile 2021 che prevede il ripristino delle attività didattiche in modalità mista (_blended_) al 30%, a partire **da lunedì 12 aprile 2021**.
- **IMPORTANTE: Rinvio Lezione del 14/04/2021**<br/>
A causa di impegni istituzionali, la lezione di **mercoledì 14 aprile 2021** è rinviata a data da destinarsi.
- **IMPORTANTE: Sospensione Attività Didattica in Presenza**<br/>
A partire da **lunedì 15 marzo 2021**, tutte le attività didattiche dei programmi di studio Sapienza si svolgeranno **esclusivamente a distanza**. Pertanto, le lezioni del corso proseguiranno solamente in modalità remota, attraverso la consueta [stanza virtuale Zoom](https://uniroma1.zoom.us/meeting/register/tZUtceCoqTgiE9AkOHCV4eMk1kv3OHPrx8Gf), secondo il calendario stabilito.<br/>
Per qualsiasi ulteriore informazione, si prega di consultare questo [link](https://www.uniroma1.it/it/notizia/covid-19-fase-3-lezioni-esami-e-lauree-presenza-e-distanza).
- **Inizio delle lezioni!**<br/>
Le lezioni del corso avranno inizio **mercoledì 24 febbraio 2021** alle ore **9:00** e si svolgeranno in modalità _blended_. Per seguire le lezioni in presenza o da remoto, si prega di consultare le istruzioni disponibili qui [sotto](#Modalità-Di-Partecipazione-Al-Corso).

## Informazioni Generali

Benvenuti sul sito web del corso di Teoria degli Algoritmi!

Il corso si svolge al secondo semestre del primo anno della [Laurea Magistrale in Matematica Applicata della Sapienza Università di Roma](https://www.mat.uniroma1.it/didattica/corsi-di-laurea/matematica-applicata-magistrale).

### Orario delle Lezioni
- **Mercoledì** dalle **9:00** alle **11:00**
- **Giovedì** dalle **11:00** alle **13:00**

### Modalità di Partecipazione al Corso
Nel rispetto delle linee guida promosse dall'Ateneo per contrastare la cosiddetta fase 3 dell'epidemia COVID-19, per l'a.a. 2020-21 il corso si terrà in modalità _blended_ (sia in presenza che a distanza). Si invitano pertanto gli studenti a prendere visione della documentazione contenente le modalità di partecipazione alle attività didattiche, disponibile al seguente [link](https://www.uniroma1.it/it/notizia/covid-19-fase-3-lezioni-esami-e-lauree-presenza-e-distanza).

#### Partecipazione in Presenza: Aula G - Edificio CU006
Gli studenti che intendono seguire il corso in presenza dovranno effettuare opportuna richiesta tramite la [App Infostud Lab](https://www.uniroma1.it/it/notizia/nuove-app-gli-studenti) oppure attraverso il sistema di prenotazione [Prodigit Sapienza](https://prodigit.uniroma1.it/), secondo le modalità e i tempi stabiliti dal [regolamento](https://www.uniroma1.it/it/notizia/covid-19-fase-3-lezioni-esami-e-lauree-presenza-e-distanza) (ulteriori informazioni sono disponibili [qui](https://www.mat.uniroma1.it/archivionotizie/prenotazioni-lezioni-su-prodigit)). Una volta confermata la propria prenotazione, dovranno recarsi presso l'**Aula G del Dipartimento di Matematica "G. Castelnuovo" [edificio CU006]**, nel giorno e nell'orario previsti per la lezione oggetto della prenotazione.

#### Partecipazione a Distanza: Zoom
Gli studenti che intendono seguire il corso in modalità a distanza potranno registrarsi alla conferenza Zoom dedicata, tramite il seguente link: https://uniroma1.zoom.us/meeting/register/tZUtceCoqTgiE9AkOHCV4eMk1kv3OHPrx8Gf

### Pagina Moodle del Corso
Gli studenti **devono** registrarsi alla pagina Moodle che si trova al seguente indirizzo web, utilizzando le stesse credenziali istituzionali (username/password) per l'accesso ai servizi Wi-Fi e Infostud: https://elearning.uniroma1.it/course/view.php?id=13101

### Orario di Ricevimento
- **Martedì** dalle **14:00** alle **16:00** presso la stanza 106 situata al I piano della Palazzina E di viale Regina Elena 295<br>
(**NOTA:** _A causa dell'emergenza sanitaria tuttora in atto, i ricevimenti in presenza sono sospesi fino a nuova comunicazione. Tuttavia, è possibile richiedere l'appuntamento per un ricevimento a distanza via Google Meet o Zoom facendone esplicita richiesta via email all'indirizzo:_ tolomei@di.uniroma1.it)

### Contatti Docente
- Email: tolomei@di.uniroma1.it
- Sito web: https://www.di.uniroma1.it/~tolomei
- Bacheca Sapienza: https://corsidilaurea.uniroma1.it/it/users/gabrieletolomeiuniroma1it

### Obiettivi del Corso
L'obiettivo del corso è duplice: da un lato, intende fornire le basi teoriche della calcolabilità e della complessità computazionale per poter riconoscere quali problemi sono risolvibili da un calcolatore mediante un _algoritmo_ e, per questi problemi, identificare la soluzione algoritmica più efficiente tra tutte quelle eventualmente possibili; dall'altro, si propone di esaminare una serie di algoritmi noti allo stato dell'arte che sono fondamentali per la risoluzione di problemi tipici dei contesti applicativi moderni, quali l'analisi dei dati su larga scala e la costruzione di modelli predittivi attraverso tecniche di _machine learning_. 

### Modalità di Esame
Lo studente potrà scegliere tra **due** diverse tipologie di esame:
-  **seminario**
-  **progetto**

Il **seminario** consiste nell'esposizione di un articolo scientifico di riferimento, a scelta tra quelli suggeriti durante il corso o, comunque, concordato preventivamente con il docente. La presentazione, della durata di 45 minuti circa e supportata da slide, dovrà evidenziare i principali risultati teorici e le conseguenti implicazioni pratiche della pubblicazione scientifica in oggetto.

Il **progetto** prevede l'implementazione di uno degli algoritmi analizzati durante il corso e la sua applicazione a un caso d'uso specifico (ad es., implementazione dell'algoritmo K-means e sua applicazione per il clustering di _tweet_). A corredo del progetto, dovrà essere fornita una breve presentazione in cui si giustifichino le scelte implementative, un'accurata analisi della complessità computazionale, nonché i risultati ottenuti per il caso d'uso scelto.<br/>
Il linguaggio di programmazione di riferimento è [Python](https://www.python.org/) (versione 3.x) in combinazione con [Jupyter Notebook](https://jupyter.org/). Tuttavia, per evitare di dover installare e configurare l'intero ambiente di sviluppo in locale sulla propria macchina, si consiglia vivamente l'utilizzo di [Google Colab](https://colab.research.google.com/).<br>
Esistono varie risorse in rete che mettono a disposizione dataset pubblici su cui applicare tecniche di _data analysis_/_machine learning_; tra queste, vale la pena suggerire:
- [Kaggle](https://www.kaggle.com/)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu)

Per entrambe le tipologie di esame, è prevista la sottomissione del materiale attraverso un'opportuna sezione della pagina Moodle del corso. In particolare, coloro che decideranno di sostenere la prova mediante seminario, dovranno inviare la presentazione (in formato **pdf**); chi, invece, opterà per lo sviluppo di un progetto software dovrà inviare sia il codice sorgente (sottoforma di file **<code>.ipynb</code>**) e tutte le relative dipendenze (ad es., file esterni utilizzati), che la breve presentazione (in formato **pdf**) a corredo.<br/> 
Il tutto dovrà avvenire entro i termini indicati per ogni specifica sessione di esame.

Infine, anche coloro che sosterranno l'esame attraverso lo sviluppo di un progetto saranno chiamati a fornire una breve presentazione orale di 20÷30 minuti circa, nella quale verranno esposti gli aspetti più rilevanti del progetto, quali ad esempio: formalizzazione del problema trattato, descrizione della/e soluzione/i adottate, criteri di valutazione, etc.

#### Idee per Seminari
La letteratura offre moltissimi spunti interessanti che possono costituire oggetto di seminari per il superamento della prova d'esame. Senza alcuna pretesa di esaustività, la lista di seguito fornisce alcuni riferimenti utili a cui attingere liberamente; si incoraggiano comunque le studentesse e gli studenti a proporre seminari su articoli scientifici al di fuori di quelli qui suggeriti.<br>
(Gli elementi <strike>depennati</strike> indicano gli argomenti che sono già stati scelti e, pertanto, non più disponibili)

- **Theory of Computation**
    - Turing, A. [_On Computable Numbers, with an Application to the Entscheidungsproblem_](http://www.cs.ox.ac.uk/activities/ieg/e-library/sources/tp2-ie.pdf)(Proceedings of the London Mathematical Society, Series 2, vol. 42, 1937)
    - <strike>Held, M. and Karp, R. M. [_The Traveling-Salesman Problem and Minimum Spanning Trees_](https://www.cse.wustl.edu/~ychen/7102/Karp-TSP.pdf) (Operations Research, 1970)</strike>
    - Cook, S. A. [_The Complexity of Theorem Proving Procedures_](http://www.cs.toronto.edu/~sacook/homepage/1971.pdf) (Theory of Computing, 1971)
    - <strike>Rabin, M. [_Probabilistic Algorithm for Testing Primality_](https://www.sciencedirect.com/science/article/pii/0022314X80900840) (Journal of Number Theory, 1980)</strike>
    - Arora, S. and Safra, S. [_Probabilistic Checking of Proofs: A New Characterization of NP_](https://www.cs.umd.edu/~gasarch/TOPICS/pcp/AS.pdf) (Journal of the ACM, 1998)

- **Clustering**
    - Kaufman, L., and Rousseeuw, P. J. [_Clustering by Means of Medoids_](https://wis.kuleuven.be/stat/robust/papers/publications-1987/kaufmanrousseeuw-clusteringbymedoids-l1norm-1987.pdf) (1987)
    - <strike>Bradley, P. S., Fayyad, U., and Reina, C. [_Scaling Clustering Algorithms to Large Databases_](https://www.aaai.org/Papers/KDD/1998/KDD98-002.pdf) (KDD, 1998)</strike>
    - <strike>Kleinberg, J. [_An Impossibility Theorem for Clustering_](https://papers.nips.cc/paper/2002/file/43e4e6a6f341e00671e123714de019a8-Paper.pdf) (NIPS, 2002)</strike>
    - <strike>Arthur, D., and Vassilvitskii, S. [_k-means++: The Advantages of Careful Seeding_](https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf) (SODA, 2007)</strike>
    - <strike>Mahajana, M., Nimbhorkara, P., and Varadarajan, K. [_The Planar k-means Problem is NP-hard_](https://www.sciencedirect.com/science/article/pii/S0304397510003269) (Theoretical Computer Science, vol. 442, 2012)</strike>

- **Learning Theory**
    - Valiant, L. G. [A Theory of the Learnable](http://web.mit.edu/6.435/www/Valiant84.pdf) (Communications of the ACM, 1984)
    - Rumelhart, D. E., Hinton, G. E., and Williams, R. J. [Learning Representations by Back-Propagating Errors](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf) (Nature, 1986)
    - Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. [Learnability and the Vapnik-Chervonenkis Dimension](http://www2.denizyuret.com/ref/blumer/ft_gateway.cfm.pdf) (Journal of the ACM, 1989)
    - <strike>Haussler, D. [Probably Approximately Correct Learning](https://www.aaai.org/Papers/AAAI/1990/AAAI90-163.pdf) (AAAI, 1990)</strike>
    - Bottou, L. [Online Algorithms and Stochastic Approximations](https://leon.bottou.org/publications/pdf/online-1998.pdf) (Online Learning and Networks, 1998)

- **Decision Trees**
    - Hyafil, L., Rivest, R. L. [Constructing Optimal Binary Decision Trees is NP-Complete](https://people.csail.mit.edu/rivest/HyafilRivest-ConstructingOptimalBinaryDecisionTreesIsNPComplete.pdf) (Information Processing Letters, 1976)
    - <strike>Mingers, J. [An Empirical Comparison of Pruning Methods
for Decision Tree Induction](https://link.springer.com/content/pdf/10.1023/A:1022604100933.pdf) (Machine Learning, 1989)</strike>
    - Breiman, L. [Bagging Predictors](https://link.springer.com/content/pdf/10.1007/BF00058655.pdf) (Machine Learning, 1996)
    
- **Graph Analysis**
    - <strike>Brin, S. and Page, L. [The Anatomy of a Large-Scale Hypertextual Web Search Engine](https://research.google/pubs/pub334.pdf) (Computer Networks, 1998)</strike>
    - Kleinberg, J. [Authoritative Sources in a Hyperlinked Environment](http://www.cs.cornell.edu/home/kleinber/auth.pdf) (Journal of the ACM, 1999)
    - Barabási, A. L. and Albert, R. [Emergence of Scaling in Random Networks](https://barabasi.com/f/67.pdf) (Science, 1999)



### Libri di Testo Consigliati
Sebbene il materiale didattico fornito a lezione sia del tutto sufficiente, per eventuali approfondimenti si consigliano i seguenti testi.
- **Teoria della Calcolabilità e Complessità**
    - _Introduction to the Theory of Computation_ [Sipser] (disponibile anche in italiano)
    - _Introduction to Theoretical Computer Science_ [Barak] (disponibile [online](https://files.boazbarak.org/introtcs/lnotes_book.pdf))
- **Machine Learning**
    - _Pattern Recognition and Machine Learning_ [Bishop]
    - _Introduction to Machine Learning_ [Alpaydin]
    - _Machine Learning_ [Murphy] 
    - _Mathematics for Machine Learning_ [Deisenroth] 

<hr>

## Syllabus 
### Parte I
- Teoria della Calcolabilità
    - Introduzione
    - Macchine di Turing
    - Decidibilità
    - Riducibilità
- Teoria della Complessità Computazionale
    - Complessità Temporale
    - Classi di Complessità
    - P vs. NP
    - NP-completezza

### Parte II
- Unsupervised Learning
    - Clustering (K-means)
    - The Curse of Dimensionality + Dimensionality Reduction (PCA)
- Supervised Learning
    - PAC Learning  
    - Linear Regression (OLS)
    - Logistic Regression (Gradient Descent)
    - Decision Trees (Recursive Binary Splitting)
- Graph Analysis
    - PageRank   

<hr>

## Materiale Didattico

| Lezione \# | Data | Argomento                                     | Materiale      | 
|------------|------|-----------------------------------------------|----------------|
| Lezione 1  | 24/02/2021 | Introduzione | [slides: <a href="./lectures/slides/01_Introduction.pdf" target="_blank">PDF</a>] |
| Lezioni 2 e 3  | 25/02/2021 - 03/03/2021| Le Macchine di Turing | [slides: <a href="./lectures/slides/02_Turing_Machines.pdf" target="_blank">PDF</a>]|
| Lezioni 4 e 5  | 04/03/2021 - 10/03/2021| Decidibilità | [slides: <a href="./lectures/slides/03_Decidability.pdf" target="_blank">PDF</a>]|
| Lezioni 6 e 7  | 11/03/2021 - 17/03/2021| Riducibilità | [slides: <a href="./lectures/slides/04_Reducibility.pdf" target="_blank">PDF</a>]|
| Lezioni 8 e 9  | 18/03/2021 - 24/03/2021| Complessità Computazionale | [slides: <a href="./lectures/slides/05_Complexity.pdf" target="_blank">PDF</a>]|
| Lezioni 10 e 11  | 25/03/2021 - 31/03/2021| Classi P e NP | [slides: <a href="./lectures/slides/06_P_vs_NP.pdf" target="_blank">PDF</a>]|
| Lezioni 12 e 13  | 07/04/2021 - 08/04/2021| NP-completezza | [slides: <a href="./lectures/slides/07_NP_Completeness.pdf" target="_blank">PDF</a>]|
| Lezione 14  | 15/04/2021 | Clustering | [slides: <a href="./lectures/slides/08_Clustering.pdf" target="_blank">PDF</a>]|
| Lezione 15  | 21/04/2021 | The Curse of Dimensionality | [slides: <a href="./lectures/slides/09_The_Curse_of_Dimensionality.pdf" target="_blank">PDF</a>]|
| Lezione 16  | 22/04/2021 | Principal Component Analysis (PCA) | [slides: <a href="./lectures/slides/10_Principal_Component_Analysis.pdf" target="_blank">PDF</a>, notes: <a href="./extras/Notes_on_Principal_Component_Analysis.pdf" target="_blank">PDF</a>]|
| Lezione 17  | 28/04/2021 | Supervised Learning | [slides: <a href="./lectures/slides/11_Supervised_Learning.pdf" target="_blank">PDF</a>]|
| Lezione 18  | 29/04/2021 | PAC Learning | [slides: <a href="./lectures/slides/12_PAC_Learning.pdf" target="_blank">PDF</a>]|
| Lezione 19  | 05/05/2021 | Linear Regression (OLS) | [slides: <a href="./lectures/slides/13_Linear_Regression.pdf" target="_blank">PDF</a>]|
| Lezioni 20 e 21  | 06/05/2021 - 12/05/2021 | Logistic Regression (Gradient Descent) | [slides: <a href="./lectures/slides/14_Logistic_Regression.pdf" target="_blank">PDF</a>, notes: <a href="./extras/Notes_on_Logistic_Regression.pdf" target="_blank">PDF</a>]|
| Lezione 22  | 13/05/2021 | Decision Trees (Recursive Binary Splitting) | [slides: <a href="./lectures/slides/15_Decision_Trees_and_Ensembles.pdf" target="_blank">PDF</a>]|
| Lezione 23  | 19/05/2021 | Graph Analysis | [slides: <a href="./lectures/slides/16_Graph_Link_Analysis.pdf" target="_blank">PDF</a>]|
| Lezione 24  | 20/05/2021 | Algoritmo PageRank | [slides: <a href="./lectures/slides/17_PageRank.pdf" target="_blank">PDF</a>, notes: <a href="./extras/Notes_on_PageRank.pdf" target="_blank">PDF</a>]|
